{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 61942,
     "status": "ok",
     "timestamp": 1683800119122,
     "user": {
      "displayName": "Wong Yun Jet",
      "userId": "09982030126116333359"
     },
     "user_tz": -480
    },
    "id": "UNCciV-vQ5cL",
    "outputId": "a8cfd491-ace9-4ea3-f277-293233d0ed0d"
   },
   "outputs": [],
   "source": [
    "# !pip install --no-deps seqeval[gpu]\n",
    "# !python -m spacy download en_core_web_lg\n",
    "# !pip install pytorch-pretrained-bert\n",
    "# !pip install PyMuPDF\n",
    "import locale\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "\n",
    "\n",
    "def getpreferredencoding(do_setlocale=True):\n",
    "    return \"UTF-8\"\n",
    "\n",
    "\n",
    "locale.getpreferredencoding = getpreferredencoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IbFZRV5cLR5V"
   },
   "source": [
    "#Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jqjtuNcFyXZ3"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6K6Oi25wKsh-"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import spacy\n",
    "from spacy.training import offsets_to_biluo_tags\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "from tqdm import trange\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
    "from pytorch_pretrained_bert import BertForTokenClassification, BertAdam\n",
    "\n",
    "from seqeval.metrics import classification_report, accuracy_score, f1_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Text preprocessing tools\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import fitz\n",
    "\n",
    "# Make each token predict result into softmax mode\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# python  -m spacy download en_core_web_lg\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8C4XQW_lL4rH"
   },
   "outputs": [],
   "source": [
    "# Adding '\\n' to the default spacy tokenizer\n",
    "prefixes = [i + \"\\\\n\" for i in nlp.Defaults.prefixes]\n",
    "prefix_regex = spacy.util.compile_prefix_regex(prefixes)\n",
    "nlp.tokenizer.prefix_search = prefix_regex.search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iYp1xhfyL6g8"
   },
   "outputs": [],
   "source": [
    "entity_dict = {\n",
    "    \"NAME\": \"Name\",\n",
    "    \"EMAIL\": \"Email Address\",\n",
    "    \"GITHUB\": \"Github\",\n",
    "    \"LOC\": \"Location\",\n",
    "    \"PHONE\": \"Phone\",\n",
    "    \"UNI\": \"University\",\n",
    "    \"DEG\": \"Degree\",\n",
    "    \"GPA\": \"GPA\",\n",
    "    \"GRADUATION_YEAR\": \"Graduation Year\",\n",
    "    \"COMPANY_MONTHS\": \"Company with Duration\",\n",
    "    \"EXPERIENCE_MONTHS\": \"Total Experience\",\n",
    "    \"DESIG\": \"Designation\",\n",
    "    \"TECHSTACK_SKILLS\": \"Technical Skills\",\n",
    "    \"PROJECT\": \"Projects\",\n",
    "    \"CERTIFICATION\": \"Certifications\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aXCWfoptLZNe"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_ner_json_to_dataframe(folder_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read all JSON files from a folder and convert them to a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        folder_path: Path to the folder containing JSON files\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame with columns: filename, content, entities\n",
    "    \"\"\"\n",
    "    data = []\n",
    "\n",
    "    # Check if folder exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"Error: Folder '{folder_path}' does not exist.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Get all JSON files from the folder\n",
    "    json_files = [f for f in os.listdir(folder_path) if f.endswith(\".json\")]\n",
    "\n",
    "    if not json_files:\n",
    "        print(f\"No JSON files found in folder '{folder_path}'\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    print(f\"Found {len(json_files)} JSON files\")\n",
    "\n",
    "    for filename in json_files:\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        try:\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                json_data = json.load(file)\n",
    "\n",
    "                # Extract content and entities\n",
    "                annotations = json_data.get(\"annotations\", [])\n",
    "\n",
    "                for annotation in annotations:\n",
    "                    content = annotation[0]  # This is the \"<text>\" string\n",
    "                    entities_dict = annotation[1]\n",
    "\n",
    "                    # Convert entities to list of tuples\n",
    "                    entities = []\n",
    "                    if \"entities\" in entities_dict:\n",
    "                        entities = [\n",
    "                            tuple(entity) for entity in entities_dict[\"entities\"]\n",
    "                        ]\n",
    "\n",
    "                    data.append(\n",
    "                        {\"filename\": filename, \"content\": content, \"entities\": entities}\n",
    "                    )\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error: Invalid JSON in file '{filename}'\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{filename}': {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    if not df.empty:\n",
    "        print(f\"\\nDataFrame created successfully with {len(df)} rows\")\n",
    "        print(\"\\nDataFrame info:\")\n",
    "        print(df.info())\n",
    "        print(\"\\nFirst few rows:\")\n",
    "        print(df.head())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_ner_json_to_dataframe(\"ner_resumes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ngo Thi Thanh Embedded Developer - AI AVATAR Ho Chi Minh Ho Chi Minh, Viet Nam - ngo.thi.thanh.09092008@gmail.com - 0923123456 - linkedin.com/in/ngo-thi-thanh-89012345 - github.com/ngothithanh I am a Cybersecurity graduate with a focus on embedded systems and IoT development. My goal is to innovate in secure embedded solutions for smart technologies. WORK EXPERIENCE AI AVATAR Ho Chi Minh Embedded Developer Designed firmware for IoT devices using C and RTOS, ensuring low power consumption. Integrated security protocols, reducing vulnerabilities by 20%. May 2020 - Present Ho Chi Minh AINKA Technology Solutions Hanoi Senior Embedded Developer Developed embedded software for industrial sensors with C++, improving data accuracy. Optimized memory usage for resource-constrained devices. Jan 2016 - Apr 2020 Hanoi EDUCATION Bachelor of Cybersecurity University of Law Hanoi GPA: 3.1/4.0 Sep 2014 - Jun 2018 PROJECTS IoT Device Firmware Description: Built firmware with C for smart home devices, enabling remote control. Outcome: Enhanced device reliability by 30% with robust code. Jun 2019 - Aug 2019 Autonomous Vehicle Control System Description: Developed a control system with Assembly for navigation. Outcome: Improved vehicle response time by 15% in real-world tests. Mar 2018 - May 2018 SKILLS Embedded: C, C++, Assembly, RTOS DevOps: Docker CERTIFICATIONS AWS Certified Solutions Architect – Associate Microsoft Certified: Azure Fundamentals'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_v7xq298Roq9"
   },
   "source": [
    "# Parser data\n",
    "- Parser data into document structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy BILUO tags: ['U-PHONE']\n",
      "BERT tokens: ['09', '##8', '##7', '##65', '##43', '##21']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'BertTokenizer' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBERT tokens: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtokenized\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Get word ids and alignment\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m encoding = \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m word_ids = encoding.word_ids()\n\u001b[32m     12\u001b[39m offset_mapping = encoding[\u001b[33m'\u001b[39m\u001b[33moffset_mapping\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[31mTypeError\u001b[39m: 'BertTokenizer' object is not callable"
     ]
    }
   ],
   "source": [
    "# Your original approach\n",
    "doc = nlp(\"0987654321\")\n",
    "biluo_tags = offsets_to_biluo_tags(doc, [(0, 10, 'PHONE')])\n",
    "print(f\"spaCy BILUO tags: {biluo_tags}\")  # ['U-PHONE']\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\", do_lower_case=False)\n",
    "text = \"0987654321\"\n",
    "tokenized = tokenizer.tokenize(text)\n",
    "print(f\"BERT tokens: {tokenized}\") \n",
    "# Get word ids and alignment\n",
    "encoding = tokenizer(text, return_offsets_mapping=True)\n",
    "word_ids = encoding.word_ids()\n",
    "offset_mapping = encoding['offset_mapping']\n",
    "\n",
    "# Create BERT labels\n",
    "def align_labels_with_tokenization(biluo_tags, tokenizer, text):\n",
    "    encoding = tokenizer(text, return_offsets_mapping=True)\n",
    "    bert_labels = []\n",
    "    \n",
    "    # For each token in the tokenization\n",
    "    for i, offset in enumerate(encoding['offset_mapping']):\n",
    "        start, end = offset\n",
    "        \n",
    "        # Special tokens get ignored\n",
    "        if start == end:\n",
    "            bert_labels.append('X')\n",
    "            continue\n",
    "            \n",
    "        # Find which spacy token this corresponds to\n",
    "        for j, (token_start, token_end) in enumerate([(0, 10)]):  # Your entities\n",
    "            if start >= token_start and end <= token_end:\n",
    "                # Check if this is first subword of entity\n",
    "                if i == 0 or encoding['offset_mapping'][i-1][1] < token_start:\n",
    "                    bert_labels.append('B-PHONE')  # Beginning\n",
    "                else:\n",
    "                    bert_labels.append('I-PHONE')  # Inside\n",
    "                break\n",
    "        else:\n",
    "            bert_labels.append('O')  # Outside\n",
    "    \n",
    "    return bert_labels\n",
    "\n",
    "# Apply the alignment\n",
    "bert_labels = align_labels_with_tokenization(biluo_tags, tokenizer, text)\n",
    "print(f\"BERT labels: {bert_labels}\")\n",
    "# Should output: ['B-PHONE', 'I-PHONE', 'I-PHONE', 'I-PHONE', 'I-PHONE', 'I-PHONE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2f9e7tXe3kWD"
   },
   "outputs": [],
   "source": [
    "def get_train_data(df):\n",
    "    tags = []\n",
    "    sentences = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        text = df[\"content\"][i]\n",
    "        entities = df[\"entities\"][i]\n",
    "        doc = nlp(text)\n",
    "\n",
    "        tag = offsets_to_biluo_tags(doc, entities)\n",
    "        tmp = pd.DataFrame([list(doc), tag]).T\n",
    "        loc = []\n",
    "        for i in range(len(tmp)):\n",
    "            if tmp[0][i].text == \".\" and tmp[1][i] == \"O\":\n",
    "                loc.append(i)\n",
    "        loc.append(len(doc))\n",
    "\n",
    "        last = 0\n",
    "        data = []\n",
    "        for pos in loc:\n",
    "            data.append([list(doc)[last:pos], tag[last:pos]])\n",
    "            last = pos\n",
    "\n",
    "        for d in data:\n",
    "            tag = [\"O\" if t == \"-\" else t for t in d[1]]\n",
    "            if len(set(tag)) > 1:\n",
    "                sentences.append(d[0])\n",
    "                tags.append(tag)\n",
    "\n",
    "    return sentences, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32618,
     "status": "ok",
     "timestamp": 1683800416527,
     "user": {
      "displayName": "Wong Yun Jet",
      "userId": "09982030126116333359"
     },
     "user_tz": -480
    },
    "id": "nFrLgTxMMeSd",
    "outputId": "10c42b92-7607-4b01-e813-1d2db4bd11e2"
   },
   "outputs": [],
   "source": [
    "sentences, tags = get_train_data(df)\n",
    "print(len(sentences), len(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 400,
     "status": "ok",
     "timestamp": 1683633592331,
     "user": {
      "displayName": "Wong Yun Jet",
      "userId": "09982030126116333359"
     },
     "user_tz": -480
    },
    "id": "OBJW6A-KTbnf",
    "outputId": "554c92d3-fb09-437e-8338-e18f9eab5570"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Abhishek, Jha, \n",
      ", Application, Development, Associate, -, Accenture, \n",
      ", \n",
      ", Bengaluru, ,, Karnataka, -, Email, me, on, Indeed, :, indeed.com/r/Abhishek-Jha/10e7a8cb732bc43a, \n",
      ", \n",
      ", •, To, work, for, an, organization, which, provides, me, the, opportunity, to, improve, my, skills, \n",
      ", and, knowledge, for, my, individual, and, company, 's, growth, in, best, possible, ways]\n",
      "['B-NAME', 'L-NAME', 'O', 'B-DESIG', 'I-DESIG', 'L-DESIG', 'O', 'U-COMPANY', 'O', 'O', 'U-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-EMAIL', 'I-EMAIL', 'I-EMAIL', 'L-EMAIL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[0])\n",
    "print(tags[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xvao3VfMMgwM"
   },
   "outputs": [],
   "source": [
    "# Find all unique tags\n",
    "tag_vals = set([\"X\", \"[CLS]\", \"[SEP]\"])\n",
    "for i in range(len(tags)):\n",
    "    tag_vals = tag_vals.union(tags[i])\n",
    "\n",
    "# tag2idx convert tag to idx, is a dict contains (tag,idx)\n",
    "tag2idx = {t: i for i, t in enumerate(tag_vals)}\n",
    "\n",
    "# idx2tag convert tag to idx, is a dict contains (idx,tag)\n",
    "idx2tag = {tag2idx[key]: key for key in tag2idx.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 396,
     "status": "ok",
     "timestamp": 1683633613923,
     "user": {
      "displayName": "Wong Yun Jet",
      "userId": "09982030126116333359"
     },
     "user_tz": -480
    },
    "id": "_dh-kwNsk1sO",
    "outputId": "20f98ee9-fdcf-419b-ebd5-46a56cd61630"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'U-EMAIL', 'I-CLG', 'U-CLG', 'B-SKILLS', 'U-LOC', 'U-SKILLS', '[CLS]', 'U-GRADYEAR', 'U-DESIG', 'L-EMAIL', 'B-YOE', 'X', 'I-NAME', 'I-SKILLS', 'I-GRADYEAR', 'B-DESIG', 'B-EMAIL', 'L-YOE', 'I-YOE', 'L-DEG', 'B-DEG', 'L-SKILLS', 'L-LOC', '[SEP]', 'L-DESIG', 'B-NAME', 'B-CLG', 'B-GRADYEAR', 'L-GRADYEAR', 'I-EMAIL', 'I-DESIG', 'B-COMPANY', 'L-NAME', 'U-YOE', 'O', 'B-LOC', 'I-LOC', 'I-COMPANY', 'L-CLG', 'I-DEG', 'U-COMPANY', 'L-COMPANY', 'U-DEG'}\n",
      "{'U-EMAIL': 0, 'I-CLG': 1, 'U-CLG': 2, 'B-SKILLS': 3, 'U-LOC': 4, 'U-SKILLS': 5, '[CLS]': 6, 'U-GRADYEAR': 7, 'U-DESIG': 8, 'L-EMAIL': 9, 'B-YOE': 10, 'X': 11, 'I-NAME': 12, 'I-SKILLS': 13, 'I-GRADYEAR': 14, 'B-DESIG': 15, 'B-EMAIL': 16, 'L-YOE': 17, 'I-YOE': 18, 'L-DEG': 19, 'B-DEG': 20, 'L-SKILLS': 21, 'L-LOC': 22, '[SEP]': 23, 'L-DESIG': 24, 'B-NAME': 25, 'B-CLG': 26, 'B-GRADYEAR': 27, 'L-GRADYEAR': 28, 'I-EMAIL': 29, 'I-DESIG': 30, 'B-COMPANY': 31, 'L-NAME': 32, 'U-YOE': 33, 'O': 34, 'B-LOC': 35, 'I-LOC': 36, 'I-COMPANY': 37, 'L-CLG': 38, 'I-DEG': 39, 'U-COMPANY': 40, 'L-COMPANY': 41, 'U-DEG': 42}\n",
      "{0: 'U-EMAIL', 1: 'I-CLG', 2: 'U-CLG', 3: 'B-SKILLS', 4: 'U-LOC', 5: 'U-SKILLS', 6: '[CLS]', 7: 'U-GRADYEAR', 8: 'U-DESIG', 9: 'L-EMAIL', 10: 'B-YOE', 11: 'X', 12: 'I-NAME', 13: 'I-SKILLS', 14: 'I-GRADYEAR', 15: 'B-DESIG', 16: 'B-EMAIL', 17: 'L-YOE', 18: 'I-YOE', 19: 'L-DEG', 20: 'B-DEG', 21: 'L-SKILLS', 22: 'L-LOC', 23: '[SEP]', 24: 'L-DESIG', 25: 'B-NAME', 26: 'B-CLG', 27: 'B-GRADYEAR', 28: 'L-GRADYEAR', 29: 'I-EMAIL', 30: 'I-DESIG', 31: 'B-COMPANY', 32: 'L-NAME', 33: 'U-YOE', 34: 'O', 35: 'B-LOC', 36: 'I-LOC', 37: 'I-COMPANY', 38: 'L-CLG', 39: 'I-DEG', 40: 'U-COMPANY', 41: 'L-COMPANY', 42: 'U-DEG'}\n"
     ]
    }
   ],
   "source": [
    "print(tag_vals)\n",
    "print(tag2idx)\n",
    "print(idx2tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Krt_ECCnR8dJ"
   },
   "source": [
    "# Make training data\n",
    "- Set GPU environment\n",
    "- Load tokenizer and tokenize\n",
    "- Set 3 embedding - Token embedding, Mask word embedding, Segmentation embedding\n",
    "- Split dataset into train and validate, then send them to DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 452,
     "status": "ok",
     "timestamp": 1683633651337,
     "user": {
      "displayName": "Wong Yun Jet",
      "userId": "09982030126116333359"
     },
     "user_tz": -480
    },
    "id": "Jpjcv-UPMp3S",
    "outputId": "efe564cd-bfd5-4935-d2d8-b6655807b290"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "n_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1556,
     "status": "ok",
     "timestamp": 1683633662364,
     "user": {
      "displayName": "Wong Yun Jet",
      "userId": "09982030126116333359"
     },
     "user_tz": -480
    },
    "id": "BgxS-xvyMrtw",
    "outputId": "aaaed706-5dd2-4a39-d187-95b085158036"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 213450/213450 [00:00<00:00, 2445182.39B/s]\n"
     ]
    }
   ],
   "source": [
    "# BERT pre-trained tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\", do_lower_case=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KorMPZTLSnc_"
   },
   "source": [
    "## Tokenizer Text\n",
    "\n",
    "- In hunggieface for bert, when come across OOV, will word piece the word.\n",
    "\n",
    "- We need to adjust the labels base on the tokenize result, “##abc” need to set label \"X\".\n",
    "\n",
    "- Need to set \"[CLS]\" at front and \"[SEP]\" at the end, as what the paper do, BERT indexer should add [CLS] and [SEP] tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EyzQTw_r3tdn"
   },
   "outputs": [],
   "source": [
    "def get_tokenized_train_data(sentences, tags):\n",
    "\n",
    "    tokenized_texts = []\n",
    "    word_piece_labels = []\n",
    "\n",
    "    for word_list, label in zip(sentences, tags):\n",
    "\n",
    "        # Add [CLS] at the front\n",
    "        temp_lable = [\"[CLS]\"]\n",
    "        temp_token = [\"[CLS]\"]\n",
    "\n",
    "        for word, lab in zip(word_list, label):\n",
    "            token_list = tokenizer.tokenize(word.text)\n",
    "            for m, token in enumerate(token_list):\n",
    "                temp_token.append(token)\n",
    "                if m == 0:\n",
    "                    temp_lable.append(lab)\n",
    "                else:\n",
    "                    temp_lable.append(\"X\")\n",
    "\n",
    "        # Add [SEP] at the end\n",
    "        temp_lable.append(\"[SEP]\")\n",
    "        temp_token.append(\"[SEP]\")\n",
    "\n",
    "        tokenized_texts.append(temp_token)\n",
    "        word_piece_labels.append(temp_lable)\n",
    "\n",
    "    return tokenized_texts, word_piece_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bGop1FFfShgC"
   },
   "outputs": [],
   "source": [
    "tokenized_texts, word_piece_labels = get_tokenized_train_data(sentences, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 405,
     "status": "ok",
     "timestamp": 1683633791062,
     "user": {
      "displayName": "Wong Yun Jet",
      "userId": "09982030126116333359"
     },
     "user_tz": -480
    },
    "id": "K1tLGZRJSjiv",
    "outputId": "54d276c1-b017-4f15-871c-6abee4117f2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'A', '##b', '##his', '##he', '##k', 'J', '##ha', 'Application', 'Development', 'Associate', '-', 'A', '##cc', '##ent', '##ure', 'Bengal', '##uru', ',', 'Karnataka', '-', 'Em', '##ail', 'me', 'on', 'Indeed', ':', 'indeed', '.', 'com', '/', 'r', '/', 'A', '##b', '##his', '##he', '##k', '-', 'J', '##ha', '/', '10', '##e', '##7', '##a', '##8', '##c', '##b', '##7', '##32', '##b', '##c', '##43', '##a', '•', 'To', 'work', 'for', 'an', 'organization', 'which', 'provides', 'me', 'the', 'opportunity', 'to', 'improve', 'my', 'skills', 'and', 'knowledge', 'for', 'my', 'individual', 'and', 'company', \"'\", 's', 'growth', 'in', 'best', 'possible', 'ways', '[SEP]']\n",
      "['[CLS]', 'B-NAME', 'X', 'X', 'X', 'X', 'L-NAME', 'X', 'B-DESIG', 'I-DESIG', 'L-DESIG', 'O', 'U-COMPANY', 'X', 'X', 'X', 'U-LOC', 'X', 'O', 'O', 'O', 'O', 'X', 'O', 'O', 'B-EMAIL', 'I-EMAIL', 'I-EMAIL', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'X', 'O', 'O', 'O', 'O', 'O', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# Vector representations of the corresponding words from the input\n",
    "print(tokenized_texts[0])\n",
    "print(word_piece_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IMo94vaSSvEk"
   },
   "source": [
    "## Set Token Embedding\n",
    "- Pad or trim the text and label to fit the need for MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 425,
     "status": "ok",
     "timestamp": 1683633801033,
     "user": {
      "displayName": "Wong Yun Jet",
      "userId": "09982030126116333359"
     },
     "user_tz": -480
    },
    "id": "s-22PV3o301V",
    "outputId": "b12ab855-7a68-49e2-93a6-b66530ccfc63"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (679 > 512). Running this sequence through BERT will result in indexing errors\n",
      "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (977 > 512). Running this sequence through BERT will result in indexing errors\n",
      "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (567 > 512). Running this sequence through BERT will result in indexing errors\n",
      "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1054 > 512). Running this sequence through BERT will result in indexing errors\n",
      "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1231 > 512). Running this sequence through BERT will result in indexing errors\n",
      "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (674 > 512). Running this sequence through BERT will result in indexing errors\n",
      "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (543 > 512). Running this sequence through BERT will result in indexing errors\n",
      "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (920 > 512). Running this sequence through BERT will result in indexing errors\n",
      "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1269 > 512). Running this sequence through BERT will result in indexing errors\n",
      "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (756 > 512). Running this sequence through BERT will result in indexing errors\n",
      "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (513 > 512). Running this sequence through BERT will result in indexing errors\n",
      "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (642 > 512). Running this sequence through BERT will result in indexing errors\n",
      "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (590 > 512). Running this sequence through BERT will result in indexing errors\n",
      "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (599 > 512). Running this sequence through BERT will result in indexing errors\n",
      "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (680 > 512). Running this sequence through BERT will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "[  101   138  1830 27516  4638  1377   147  2328 22491  3273  9666   118\n",
      "   138 19515  3452  3313  7756 12328   117 12247   118 18653 11922  1143\n",
      "  1113 10364   131  5750   119  3254   120   187   120   138  1830 27516\n",
      "  4638  1377   118   147  2328   120  1275  1162  1559  1161  1604  1665\n",
      "  1830  1559 17101  1830  1665 25631  1161   794  1706  1250  1111  1126\n",
      "  2369  1134  2790  1143  1103  3767  1106  4607  1139  4196  1105  3044\n",
      "  1111  1139  2510  1105  1419   112   188  3213  1107  1436  1936  3242\n",
      "   102     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 512\n",
    "bs = 4\n",
    "\n",
    "# Make text tokens into ids\n",
    "input_ids = pad_sequences(\n",
    "    [tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
    "    maxlen=MAX_LEN,\n",
    "    dtype=\"long\",\n",
    "    truncating=\"post\",\n",
    "    padding=\"post\",\n",
    ")\n",
    "print(len(input_ids[0]))\n",
    "print(input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1407,
     "status": "ok",
     "timestamp": 1683633807374,
     "user": {
      "displayName": "Wong Yun Jet",
      "userId": "09982030126116333359"
     },
     "user_tz": -480
    },
    "id": "bCwtmUeb_KjT",
    "outputId": "f1f5ea29-2e8d-4a2b-e7ba-5931431468f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "[ 6 25 11 11 11 11 32 11 15 30 24 34 40 11 11 11  4 11 34 34 34 34 11 34\n",
      " 34 16 29 29 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34 11 34 34 34 34 34 23 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34 34 34]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "pad_sequences -> https://www.tensorflow.org/api_docs/python/tf/keras/utils/pad_sequences\n",
    "====================\n",
    "maxlen=512: maximum length of all sequences\n",
    "padding    ='post': pad after each sequence\n",
    "truncating ='post': remove values from sequences larger than maxlen at the end of the sequences\n",
    "\n",
    "convert_tokens_to_ids -> converts a string to a sequence of ids (int)\n",
    "\"\"\"\n",
    "\n",
    "tags = pad_sequences(\n",
    "    [[tag2idx.get(l) for l in lab] for lab in word_piece_labels],\n",
    "    maxlen=MAX_LEN,\n",
    "    value=tag2idx[\"O\"],\n",
    "    padding=\"post\",\n",
    "    dtype=\"long\",\n",
    "    truncating=\"post\",\n",
    ")\n",
    "print(len(tags[0]))\n",
    "print(tags[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A_GZkJj-TBRX"
   },
   "source": [
    "## Set Mask Word Embeeding\n",
    "- For fine tune of predict, with token mask is 1, pad token is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1123,
     "status": "ok",
     "timestamp": 1683633840086,
     "user": {
      "displayName": "Wong Yun Jet",
      "userId": "09982030126116333359"
     },
     "user_tz": -480
    },
    "id": "Djia1vFfntTl",
    "outputId": "49e00bc4-4ec0-48b8-f4b0-ff2ee21256e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# if the current value >0, then assign 1, else =0\n",
    "attention_masks = [[float(i > 0) for i in ii] for ii in input_ids]\n",
    "print(attention_masks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O26057JiTOW-"
   },
   "source": [
    "## Split data into Train and Validate\n",
    "- 70% for training, 30% for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ltnloMgxqmCQ"
   },
   "outputs": [],
   "source": [
    "# train inputs, validation inputs, train tags, validation tags, train masks, validation masks\n",
    "tr_inputs, val_inputs, tr_tags, val_tags, tr_masks, val_masks = train_test_split(\n",
    "    input_ids, tags, attention_masks, random_state=2000, test_size=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1683633896940,
     "user": {
      "displayName": "Wong Yun Jet",
      "userId": "09982030126116333359"
     },
     "user_tz": -480
    },
    "id": "oDkL4P0kTce_",
    "outputId": "07493ae8-76ab-4506-f3d1-880fae090741"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(545, 234, 545, 234, 545, 234)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tr_inputs), len(val_inputs), len(tr_tags), len(val_tags), len(tr_masks), len(\n",
    "    val_masks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3tOJPf6UTsKL"
   },
   "source": [
    "### Set data into tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2oBhftchoEng"
   },
   "outputs": [],
   "source": [
    "tr_inputs = torch.tensor(tr_inputs)\n",
    "val_inputs = torch.tensor(val_inputs)\n",
    "tr_tags = torch.tensor(tr_tags)\n",
    "val_tags = torch.tensor(val_tags)\n",
    "tr_masks = torch.tensor(tr_masks)\n",
    "val_masks = torch.tensor(val_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Co1bYql3TzEK"
   },
   "source": [
    "### Put data into Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gZUw0kZhuPn7"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TORCH.UTILS.DATA -> https://pytorch.org/docs/stable/data.html\n",
    "\n",
    "TensorDataset: Dataset wrapping tensors. Each sample will be retrieved by indexing tensors along the first dimension.\n",
    "RandomSampler: Samples elements randomly\n",
    "DataLoader   : Python iterable over a dataset\n",
    "\n",
    "Notes: Only set token embeeding, attention embedding, no segment embedding\n",
    "\"\"\"\n",
    "\n",
    "train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=bs)\n",
    "\n",
    "valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
    "valid_sampler = SequentialSampler(valid_data)\n",
    "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cGrUClN7UAqz"
   },
   "source": [
    "# Train Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17978,
     "status": "ok",
     "timestamp": 1683634013903,
     "user": {
      "displayName": "Wong Yun Jet",
      "userId": "09982030126116333359"
     },
     "user_tz": -480
    },
    "id": "PaJDiVCItdGI",
    "outputId": "3400c11e-ac90-44fd-ea91-e650f80af005"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 404400730/404400730 [00:08<00:00, 48381462.02B/s]\n"
     ]
    }
   ],
   "source": [
    "# Defining the model\n",
    "bert_model = BertForTokenClassification.from_pretrained(\n",
    "    \"bert-base-cased\", num_labels=len(tag2idx)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5rWymqnLtkec"
   },
   "outputs": [],
   "source": [
    "# Set model to GPU\n",
    "bert_model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T9Q6usKMU7T9"
   },
   "source": [
    "### Set Fine-Tuning method\n",
    "- Manual optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UfxcGY1eCwV3"
   },
   "outputs": [],
   "source": [
    "FULL_FINETUNING = True\n",
    "# If full tuning=True: Fine tuning all the layers\n",
    "if FULL_FINETUNING:\n",
    "    param_optimizer = list(bert_model.named_parameters())\n",
    "    no_decay = [\"bias\", \"gamma\", \"beta\"]\n",
    "\n",
    "    # n=name, p=parameter\n",
    "    optimizer_grouped_parameters = [\n",
    "        # Params that not inside no_decay\n",
    "        {\n",
    "            \"params\": [\n",
    "                p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n",
    "            ],\n",
    "            \"weight_decay_rate\": 0.01,\n",
    "        },\n",
    "        # Params that are inside no_decay\n",
    "        {\n",
    "            \"params\": [\n",
    "                p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n",
    "            ],\n",
    "            \"weight_decay_rate\": 0.0,\n",
    "        },\n",
    "    ]\n",
    "\n",
    "# If full tuning=False -> Not full tuning, only fine tune classifier params\n",
    "else:\n",
    "    param_optimizer = list(bert_model.named_parameters())\n",
    "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
    "\n",
    "# Optimizer and learning scheduler\n",
    "optimizer = Adam(optimizer_grouped_parameters, lr=3e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QLK-_vGBVZC9"
   },
   "source": [
    "### Fine-Tuning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 623333,
     "status": "ok",
     "timestamp": 1683635758965,
     "user": {
      "displayName": "Wong Yun Jet",
      "userId": "09982030126116333359"
     },
     "user_tz": -480
    },
    "id": "ZVjHhbPzJelT",
    "outputId": "152d4de5-bbed-4f3f-d01c-9db1f3626d95"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  10%|█         | 1/10 [01:02<09:23, 62.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.012598166418564335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch:  20%|██        | 2/10 [02:04<08:18, 62.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.01448450641397278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch:  30%|███       | 3/10 [03:06<07:15, 62.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.01193943092247716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch:  40%|████      | 4/10 [04:09<06:13, 62.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.01086661145966296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch:  50%|█████     | 5/10 [05:11<05:11, 62.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.011256178366198768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch:  60%|██████    | 6/10 [06:13<04:08, 62.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.00856177856048219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch:  70%|███████   | 7/10 [07:15<03:06, 62.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.008043766321051853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch:  80%|████████  | 8/10 [08:17<02:04, 62.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.006707057559923914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch:  90%|█████████ | 9/10 [09:19<01:02, 62.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.007049659804851462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 10/10 [10:21<00:00, 62.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0072043191242825416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Set epoch and grad max num\n",
    "epochs = 10\n",
    "max_grad_norm = 1.0\n",
    "\n",
    "for _ in trange(epochs, desc=\"Epoch\"):\n",
    "    # Train loop\n",
    "    bert_model.train()\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        # Forward pass\n",
    "        loss = bert_model(\n",
    "            b_input_ids,\n",
    "            token_type_ids=None,\n",
    "            attention_mask=b_input_mask,\n",
    "            labels=b_labels,\n",
    "        )\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Track train loss\n",
    "        tr_loss += loss.item()\n",
    "\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "\n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            parameters=bert_model.parameters(), max_norm=max_grad_norm\n",
    "        )\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        bert_model.zero_grad()\n",
    "\n",
    "    # Print train loss per epoch\n",
    "    print(\"Train loss: {}\".format(tr_loss / nb_tr_steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Z1v6jatHy05"
   },
   "source": [
    "# Save Bert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O3v-lHOQV2jP"
   },
   "outputs": [],
   "source": [
    "bert_out_address = \"/content/drive/MyDrive/Colab Notebooks/NLP/BERT/models/\"\n",
    "\n",
    "# Save a trained model, configuration and tokenizer\n",
    "model_to_save = bert_model.module if hasattr(bert_model, \"module\") else bert_model\n",
    "\n",
    "output_model_file = (\n",
    "    \"/content/drive/MyDrive/Colab Notebooks/NLP/BERT/models/pytorch_model.bin\"\n",
    ")\n",
    "output_config_file = (\n",
    "    \"/content/drive/MyDrive/Colab Notebooks/NLP/BERT/models/config.json\"\n",
    ")\n",
    "\n",
    "# Save model into file\n",
    "torch.save(model_to_save.state_dict(), output_model_file)\n",
    "\n",
    "model_to_save.config.to_json_file(output_config_file)\n",
    "\n",
    "tokenizer.save_vocabulary(bert_out_address)\n",
    "\n",
    "# Load back the bert model\n",
    "bert_model = BertForTokenClassification.from_pretrained(\n",
    "    bert_out_address, num_labels=len(tag2idx)\n",
    ")\n",
    "\n",
    "bert_model.cuda()\n",
    "\n",
    "if n_gpu > 1:\n",
    "    bert_model = torch.nn.DataParallel(bert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GegxpwJBVBVD"
   },
   "outputs": [],
   "source": [
    "bert_out_address = \"/content/drive/MyDrive/Colab Notebooks/NLP/BERT/models/\"\n",
    "# Load back the bert model\n",
    "bert_model = BertForTokenClassification.from_pretrained(\n",
    "    bert_out_address, num_labels=len(tag2idx)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1cMtf0mOXd16"
   },
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9174,
     "status": "ok",
     "timestamp": 1683636183688,
     "user": {
      "displayName": "Wong Yun Jet",
      "userId": "09982030126116333359"
     },
     "user_tz": -480
    },
    "id": "ZLEYI60sPUrT",
    "outputId": "2d94824a-7d88-4d06-f835-8ca2ff5b2627"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 socre: 0.532571\n",
      "Accuracy score: 0.859883\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CLG     0.3068    0.4154    0.3529        65\n",
      "     COMPANY     0.6194    0.5963    0.6076       161\n",
      "         DEG     0.5116    0.6567    0.5752        67\n",
      "       DESIG     0.4890    0.6846    0.5705       130\n",
      "       EMAIL     0.5405    0.4167    0.4706        48\n",
      "    GRADYEAR     0.6000    0.3889    0.4719        54\n",
      "         LOC     0.7791    0.5929    0.6734       113\n",
      "        NAME     0.9296    0.9041    0.9167        73\n",
      "      SKILLS     0.2179    0.2957    0.2509       115\n",
      "         YOE     0.4000    0.2222    0.2857         9\n",
      "           _     0.0000    0.0000    0.0000         0\n",
      "\n",
      "   micro avg     0.5093    0.5581    0.5326       835\n",
      "   macro avg     0.4904    0.4703    0.4705       835\n",
      "weighted avg     0.5514    0.5581    0.5461       835\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate loop\n",
    "bert_model.eval()\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "for batch in valid_dataloader:\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    input_ids, input_mask, label_ids = batch\n",
    "\n",
    "    \"\"\"\n",
    "  no_grad: context-manager that disabled gradient calculation (disabling gradient calc is useful for inference when u r \n",
    "  sure that u will not call Tensor.backward() -> reduce memory consumption for computations)\n",
    "  https://pytorch.org/docs/stable/generated/torch.no_grad.html\n",
    "  \"\"\"\n",
    "    with torch.no_grad():\n",
    "        # logits are the output of the BERT model before a software activation function is applied to the output of BERT\n",
    "        logits = bert_model(\n",
    "            input_ids,\n",
    "            token_type_ids=None,\n",
    "            attention_mask=input_mask,\n",
    "        )\n",
    "\n",
    "    # Get NER predict result\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    logits = [list(p) for p in np.argmax(logits, axis=2)]\n",
    "\n",
    "    # Get NER true result\n",
    "    label_ids = label_ids.to(\"cpu\").numpy()\n",
    "\n",
    "    # Only predict real word, mark=0 will not calculate\n",
    "    input_mask = input_mask.to(\"cpu\").numpy()\n",
    "\n",
    "    # Compare the valuable predict result\n",
    "    for i, mask in enumerate(input_mask):\n",
    "        temp_1 = []  # Real one\n",
    "        temp_2 = []  # Predict one\n",
    "\n",
    "        for j, m in enumerate(mask):\n",
    "            # Mark=0 meaning its a pad word then no need compare\n",
    "            if m:\n",
    "                if (\n",
    "                    idx2tag[label_ids[i][j]] != \"X\"\n",
    "                    and idx2tag[label_ids[i][j]] != \"[CLS]\"\n",
    "                    and idx2tag[label_ids[i][j]] != \"[SEP]\"\n",
    "                ):\n",
    "                    temp_1.append(idx2tag[label_ids[i][j]])\n",
    "                    temp_2.append(idx2tag[logits[i][j]])\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        y_true.append(temp_1)\n",
    "        y_pred.append(temp_2)\n",
    "print(\"f1 socre: %f\" % (f1_score(y_true, y_pred)))\n",
    "print(\"Accuracy score: %f\" % (accuracy_score(y_true, y_pred)))\n",
    "print(classification_report(y_true, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S4Bh9Q9tBVpp"
   },
   "source": [
    "BERT preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RmNV8XAx5y8r"
   },
   "outputs": [],
   "source": [
    "# JSON formatting functions\n",
    "import logging\n",
    "import re\n",
    "\n",
    "\n",
    "def convert_dataturks_to_spacy(dataturks_JSON_FilePath):\n",
    "    try:\n",
    "        training_data = []\n",
    "        lines = []\n",
    "        with open(dataturks_JSON_FilePath, \"r\", encoding=\"utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        for line in lines:\n",
    "            data = json.loads(line)\n",
    "            text = data[\"content\"].replace(\"\\n\", \" \")\n",
    "            entities = []\n",
    "            data_annotations = data[\"annotation\"]\n",
    "            if data_annotations is not None:\n",
    "                for annotation in data_annotations:\n",
    "                    # only a single point in text annotation.\n",
    "                    point = annotation[\"points\"][0]\n",
    "                    labels = annotation[\"label\"]\n",
    "                    # handle both list of labels or a single label.\n",
    "                    if not isinstance(labels, list):\n",
    "                        labels = [labels]\n",
    "\n",
    "                    for label in labels:\n",
    "                        point_start = point[\"start\"]\n",
    "                        point_end = point[\"end\"]\n",
    "                        point_text = point[\"text\"]\n",
    "\n",
    "                        lstrip_diff = len(point_text) - len(point_text.lstrip())\n",
    "                        rstrip_diff = len(point_text) - len(point_text.rstrip())\n",
    "                        if lstrip_diff != 0:\n",
    "                            point_start = point_start + lstrip_diff\n",
    "                        if rstrip_diff != 0:\n",
    "                            point_end = point_end - rstrip_diff\n",
    "                        entities.append((point_start, point_end + 1, label))\n",
    "            training_data.append((text, {\"entities\": entities}))\n",
    "        return training_data\n",
    "    except Exception as e:\n",
    "        logging.exception(\n",
    "            \"Unable to process \" + dataturks_JSON_FilePath + \"\\n\" + \"error = \" + str(e)\n",
    "        )\n",
    "        return None\n",
    "\n",
    "\n",
    "def trim_entity_spans(data: list) -> list:\n",
    "    \"\"\"Removes leading and trailing white spaces from entity spans.\n",
    "\n",
    "    Args:\n",
    "        data (list): The data to be cleaned in spaCy JSON format.\n",
    "\n",
    "    Returns:\n",
    "        list: The cleaned data.\n",
    "    \"\"\"\n",
    "    invalid_span_tokens = re.compile(r\"\\s\")\n",
    "\n",
    "    cleaned_data = []\n",
    "    for text, annotations in data:\n",
    "        entities = annotations[\"entities\"]\n",
    "        valid_entities = []\n",
    "        for start, end, label in entities:\n",
    "            valid_start = start\n",
    "            valid_end = end\n",
    "            while valid_start < len(text) and invalid_span_tokens.match(\n",
    "                text[valid_start]\n",
    "            ):\n",
    "                valid_start += 1\n",
    "            while valid_end > 1 and invalid_span_tokens.match(text[valid_end - 1]):\n",
    "                valid_end -= 1\n",
    "            valid_entities.append([valid_start, valid_end, label])\n",
    "        cleaned_data.append([text, {\"entities\": valid_entities}])\n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 464,
     "status": "ok",
     "timestamp": 1683643292378,
     "user": {
      "displayName": "Wong Yun Jet",
      "userId": "09982030126116333359"
     },
     "user_tz": -480
    },
    "id": "iT2j_9A56NeF",
    "outputId": "1f1a366e-0df2-4142-c70a-1ded58800b3e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Abhishek Jha Application Development Associate - Accenture  Bengaluru, Karnataka - Email me on Indeed: indeed.com/r/Abhishek-Jha/10e7a8cb732bc43a  • To work for an organization which provides me the opportunity to improve my skills and knowledge for my individual and company's growth in best possible ways.  Willing to relocate to: Bangalore, Karnataka  WORK EXPERIENCE  Application Development Associate  Accenture -  November 2017 to Present  Role: Currently working on Chat-bot. Developing Backend Oracle PeopleSoft Queries for the Bot which will be triggered based on given input. Also, Training the bot for different possible utterances (Both positive and negative), which will be given as input by the user.  EDUCATION  B.E in Information science and engineering  B.v.b college of engineering and technology -  Hubli, Karnataka  August 2013 to June 2017  12th in Mathematics  Woodbine modern school  April 2011 to March 2013  10th  Kendriya Vidyalaya  April 2001 to March 2011  SKILLS  C (Less than 1 year), Database (Less than 1 year), Database Management (Less than 1 year), Database Management System (Less than 1 year), Java (Less than 1 year)  ADDITIONAL INFORMATION  Technical Skills  https://www.indeed.com/r/Abhishek-Jha/10e7a8cb732bc43a?isid=rex-download&ikw=download-top&co=IN   • Programming language: C, C++, Java • Oracle PeopleSoft • Internet Of Things • Machine Learning • Database Management System • Computer Networks • Operating System worked on: Linux, Windows, Mac  Non - Technical Skills  • Honest and Hard-Working • Tolerant and Flexible to Different Situations • Polite and Calm • Team-Player\",\n",
       " {'entities': [[1296, 1622, 'Skills'],\n",
       "   [993, 1154, 'Skills'],\n",
       "   [939, 957, 'College Name'],\n",
       "   [883, 905, 'College Name'],\n",
       "   [856, 860, 'Graduation Year'],\n",
       "   [771, 814, 'College Name'],\n",
       "   [727, 769, 'Designation'],\n",
       "   [407, 416, 'Companies worked at'],\n",
       "   [372, 405, 'Designation'],\n",
       "   [95, 145, 'Email Address'],\n",
       "   [60, 69, 'Location'],\n",
       "   [49, 58, 'Companies worked at'],\n",
       "   [13, 46, 'Designation'],\n",
       "   [0, 12, 'Name']]}]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = trim_entity_spans(convert_dataturks_to_spacy(data_file_address))\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDY0e4qRYyIl"
   },
   "source": [
    "# Inference\n",
    "- After we trained a model, we can make it into service, sending the new resume then get the prediction.\n",
    "\n",
    "Process\n",
    "\n",
    "1) Load model\n",
    "\n",
    "2) Load tokenizer\n",
    "\n",
    "3) Set test query (PDF file)\n",
    "\n",
    "4) Make query into embedding\n",
    "\n",
    "5) Predict with model\n",
    "\n",
    "6) Parser result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "duMnYIF64KPL"
   },
   "outputs": [],
   "source": [
    "def getWordnetPos(words):\n",
    "    tag = pos_tag([words])[0][1][0].upper()\n",
    "    tag_dict = {\n",
    "        \"J\": wordnet.ADJ,\n",
    "        \"N\": wordnet.NOUN,\n",
    "        \"V\": wordnet.VERB,\n",
    "        \"R\": wordnet.ADV,\n",
    "    }\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "\n",
    "def cv_preprocessing(cv_data):\n",
    "    # Tokenization\n",
    "    tokenized_text = word_tokenize(cv_data)\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    filter_text = []\n",
    "    for token in tokenized_text:\n",
    "        if token not in stop_words:\n",
    "            filter_text.append(token)\n",
    "\n",
    "    # POS and lemmatize\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatizeResults = [\n",
    "        lemmatizer.lemmatize(token, getWordnetPos(token)) for token in filter_text\n",
    "    ]\n",
    "    return \" \".join(lemmatizeResults)\n",
    "\n",
    "\n",
    "def pdftotext(m, preprocessing=False):\n",
    "    # Open pdf file\n",
    "    doc = fitz.open(m)\n",
    "\n",
    "    # Convert pdf to text\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "\n",
    "    # Remove new line\n",
    "    text = \" \".join(text.split(\"\\n\"))\n",
    "\n",
    "    if preprocessing:\n",
    "        return cv_preprocessing(text)\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r9nqqCF5kaLs"
   },
   "outputs": [],
   "source": [
    "def bert_predict(cv_data: str):\n",
    "    # Token id embeddig, mask word embeddig\n",
    "    tokenized_texts = []\n",
    "    temp_token = []\n",
    "\n",
    "    # Add [CLS] at the front\n",
    "    temp_token.append(\"[CLS]\")\n",
    "    token_list = tokenizer.tokenize(cv_data)\n",
    "\n",
    "    for m, token in enumerate(token_list):\n",
    "        temp_token.append(token)\n",
    "\n",
    "    # Trim the token to fit the length requirement\n",
    "    if len(temp_token) > MAX_LEN - 1:\n",
    "        temp_token = temp_token[: MAX_LEN - 1]\n",
    "\n",
    "    # Add [SEP] at the end\n",
    "    temp_token.append(\"[SEP]\")\n",
    "\n",
    "    tokenized_texts.append(temp_token)\n",
    "\n",
    "    # Make id embedding\n",
    "    input_ids = pad_sequences(\n",
    "        [tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
    "        maxlen=MAX_LEN,\n",
    "        dtype=\"long\",\n",
    "        truncating=\"post\",\n",
    "        padding=\"post\",\n",
    "    )\n",
    "    # Make mask embeeding -> For fine tune of predict, with token mask is 1, pad token is 0\n",
    "    attention_masks = [[float(i > 0) for i in ii] for ii in input_ids]\n",
    "    segment_ids = [[0] * len(input_id) for input_id in input_ids]\n",
    "\n",
    "    # Make embeddings into torch tensor\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_masks = torch.tensor(attention_masks)\n",
    "    segment_ids = torch.tensor(segment_ids)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(\n",
    "            input_ids.cuda(),\n",
    "            token_type_ids=None,\n",
    "            attention_mask=None,\n",
    "        )\n",
    "        # For eval mode, the first result of outputs is logits\n",
    "        logits = outputs[0]\n",
    "\n",
    "    predict_results = logits.detach().cpu().numpy()\n",
    "    results_arrays_soft = softmax(\n",
    "        predict_results\n",
    "    )  # Make each token predict result into softmax mode\n",
    "    result_array = results_arrays_soft\n",
    "    result_list = np.argmax(result_array, axis=-1)\n",
    "\n",
    "    # Get token predict tag\n",
    "    for i, mark in enumerate(attention_masks[0]):\n",
    "        if mark > 0:\n",
    "            print(f\"{temp_token[i]:50} {idx2tag[result_list[i]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C8-hhrt2AjCX"
   },
   "source": [
    "# Test with one train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2251,
     "status": "ok",
     "timestamp": 1683644048343,
     "user": {
      "displayName": "Wong Yun Jet",
      "userId": "09982030126116333359"
     },
     "user_tz": -480
    },
    "id": "Lt0QDHiwARvN",
    "outputId": "fc282953-a811-4e1e-a673-df6e7ee74502"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]                                              [CLS]\n",
      "A                                                  B-NAME\n",
      "##b                                                X\n",
      "##his                                              X\n",
      "##he                                               X\n",
      "##k                                                X\n",
      "J                                                  L-NAME\n",
      "##ha                                               X\n",
      "Application                                        B-DESIG\n",
      "Development                                        I-DESIG\n",
      "Associate                                          L-DESIG\n",
      "-                                                  O\n",
      "A                                                  O\n",
      "##cc                                               X\n",
      "##ent                                              X\n",
      "##ure                                              X\n",
      "Bengal                                             U-LOC\n",
      "##uru                                              X\n",
      ",                                                  O\n",
      "Karnataka                                          O\n",
      "-                                                  O\n",
      "Em                                                 O\n",
      "##ail                                              X\n",
      "me                                                 O\n",
      "on                                                 O\n",
      "Indeed                                             O\n",
      ":                                                  O\n",
      "indeed                                             O\n",
      ".                                                  X\n",
      "com                                                X\n",
      "/                                                  X\n",
      "r                                                  X\n",
      "/                                                  X\n",
      "A                                                  X\n",
      "##b                                                X\n",
      "##his                                              X\n",
      "##he                                               X\n",
      "##k                                                X\n",
      "-                                                  X\n",
      "J                                                  X\n",
      "##ha                                               X\n",
      "/                                                  X\n",
      "10                                                 X\n",
      "##e                                                X\n",
      "##7                                                X\n",
      "##a                                                X\n",
      "##8                                                X\n",
      "##c                                                X\n",
      "##b                                                X\n",
      "##7                                                X\n",
      "##32                                               X\n",
      "##b                                                X\n",
      "##c                                                X\n",
      "##43                                               X\n",
      "##a                                                X\n",
      "•                                                  O\n",
      "To                                                 O\n",
      "work                                               O\n",
      "for                                                O\n",
      "an                                                 O\n",
      "organization                                       O\n",
      "which                                              O\n",
      "provides                                           O\n",
      "me                                                 O\n",
      "the                                                O\n",
      "opportunity                                        O\n",
      "to                                                 O\n",
      "improve                                            O\n",
      "my                                                 O\n",
      "skills                                             O\n",
      "and                                                O\n",
      "knowledge                                          O\n",
      "for                                                O\n",
      "my                                                 O\n",
      "individual                                         O\n",
      "and                                                O\n",
      "company                                            O\n",
      "'                                                  O\n",
      "s                                                  X\n",
      "growth                                             O\n",
      "in                                                 O\n",
      "best                                               O\n",
      "possible                                           O\n",
      "ways                                               O\n",
      ".                                                  O\n",
      "Will                                               O\n",
      "##ing                                              X\n",
      "to                                                 O\n",
      "relocate                                           O\n",
      "to                                                 O\n",
      ":                                                  O\n",
      "Bangalore                                          O\n",
      ",                                                  O\n",
      "Karnataka                                          O\n",
      "W                                                  O\n",
      "##OR                                               X\n",
      "##K                                                X\n",
      "E                                                  O\n",
      "##X                                                X\n",
      "##P                                                X\n",
      "##ER                                               X\n",
      "##IE                                               X\n",
      "##NC                                               X\n",
      "##E                                                X\n",
      "Application                                        B-DESIG\n",
      "Development                                        I-DESIG\n",
      "Associate                                          L-DESIG\n",
      "A                                                  O\n",
      "##cc                                               X\n",
      "##ent                                              X\n",
      "##ure                                              X\n",
      "-                                                  O\n",
      "November                                           O\n",
      "2017                                               O\n",
      "to                                                 O\n",
      "Present                                            O\n",
      "Role                                               O\n",
      ":                                                  O\n",
      "Currently                                          O\n",
      "working                                            O\n",
      "on                                                 O\n",
      "Cha                                                O\n",
      "##t                                                X\n",
      "-                                                  O\n",
      "b                                                  O\n",
      "##ot                                               X\n",
      ".                                                  O\n",
      "Dev                                                O\n",
      "##elo                                              X\n",
      "##ping                                             X\n",
      "Back                                               O\n",
      "##end                                              X\n",
      "Oracle                                             U-COMPANY\n",
      "People                                             O\n",
      "##S                                                X\n",
      "##oft                                              X\n",
      "Que                                                O\n",
      "##ries                                             X\n",
      "for                                                O\n",
      "the                                                O\n",
      "Bo                                                 O\n",
      "##t                                                X\n",
      "which                                              O\n",
      "will                                               O\n",
      "be                                                 O\n",
      "triggered                                          O\n",
      "based                                              O\n",
      "on                                                 O\n",
      "given                                              O\n",
      "input                                              O\n",
      ".                                                  [SEP]\n",
      "Also                                               O\n",
      ",                                                  O\n",
      "Training                                           O\n",
      "the                                                O\n",
      "b                                                  O\n",
      "##ot                                               X\n",
      "for                                                O\n",
      "different                                          O\n",
      "possible                                           O\n",
      "utter                                              O\n",
      "##ance                                             X\n",
      "##s                                                X\n",
      "(                                                  O\n",
      "Both                                               X\n",
      "positive                                           O\n",
      "and                                                O\n",
      "negative                                           O\n",
      ")                                                  O\n",
      ",                                                  O\n",
      "which                                              O\n",
      "will                                               O\n",
      "be                                                 O\n",
      "given                                              O\n",
      "as                                                 O\n",
      "input                                              O\n",
      "by                                                 O\n",
      "the                                                O\n",
      "user                                               O\n",
      ".                                                  O\n",
      "E                                                  O\n",
      "##D                                                X\n",
      "##UC                                               X\n",
      "##AT                                               X\n",
      "##ION                                              X\n",
      "B                                                  B-DEG\n",
      ".                                                  X\n",
      "E                                                  X\n",
      "in                                                 I-DEG\n",
      "Information                                        I-DEG\n",
      "science                                            I-DEG\n",
      "and                                                I-DEG\n",
      "engineering                                        I-DEG\n",
      "B                                                  B-CLG\n",
      ".                                                  X\n",
      "v                                                  X\n",
      ".                                                  X\n",
      "b                                                  X\n",
      "college                                            I-CLG\n",
      "of                                                 I-CLG\n",
      "engineering                                        I-CLG\n",
      "and                                                I-CLG\n",
      "technology                                         L-CLG\n",
      "-                                                  O\n",
      "Hu                                                 O\n",
      "##b                                                X\n",
      "##li                                               X\n",
      ",                                                  O\n",
      "Karnataka                                          O\n",
      "August                                             O\n",
      "2013                                               O\n",
      "to                                                 O\n",
      "June                                               O\n",
      "2017                                               U-GRADYEAR\n",
      "12th                                               O\n",
      "in                                                 O\n",
      "Mathematics                                        O\n",
      "Wood                                               B-CLG\n",
      "##bine                                             X\n",
      "modern                                             I-CLG\n",
      "school                                             I-CLG\n",
      "April                                              O\n",
      "2011                                               O\n",
      "to                                                 O\n",
      "March                                              O\n",
      "2013                                               U-GRADYEAR\n",
      "10th                                               O\n",
      "Ken                                                B-CLG\n",
      "##dr                                               X\n",
      "##iya                                              X\n",
      "V                                                  L-CLG\n",
      "##idy                                              X\n",
      "##alaya                                            X\n",
      "April                                              O\n",
      "2001                                               O\n",
      "to                                                 O\n",
      "March                                              O\n",
      "2011                                               O\n",
      "SK                                                 O\n",
      "##IL                                               X\n",
      "##LS                                               X\n",
      "C                                                  B-SKILLS\n",
      "(                                                  I-SKILLS\n",
      "Less                                               X\n",
      "than                                               I-SKILLS\n",
      "1                                                  I-SKILLS\n",
      "year                                               I-SKILLS\n",
      ")                                                  I-SKILLS\n",
      ",                                                  I-SKILLS\n",
      "Database                                           I-SKILLS\n",
      "(                                                  I-SKILLS\n",
      "Less                                               X\n",
      "than                                               I-SKILLS\n",
      "1                                                  I-SKILLS\n",
      "year                                               I-SKILLS\n",
      ")                                                  I-SKILLS\n",
      ",                                                  I-SKILLS\n",
      "Database                                           I-SKILLS\n",
      "Management                                         I-SKILLS\n",
      "(                                                  I-SKILLS\n",
      "Less                                               X\n",
      "than                                               I-SKILLS\n",
      "1                                                  I-SKILLS\n",
      "year                                               I-SKILLS\n",
      ")                                                  I-SKILLS\n",
      ",                                                  I-SKILLS\n",
      "Database                                           I-SKILLS\n",
      "Management                                         I-SKILLS\n",
      "System                                             I-SKILLS\n",
      "(                                                  I-SKILLS\n",
      "Less                                               X\n",
      "than                                               I-SKILLS\n",
      "1                                                  I-SKILLS\n",
      "year                                               I-SKILLS\n",
      ")                                                  I-SKILLS\n",
      ",                                                  I-SKILLS\n",
      "Java                                               I-SKILLS\n",
      "(                                                  I-SKILLS\n",
      "Less                                               X\n",
      "than                                               I-SKILLS\n",
      "1                                                  I-SKILLS\n",
      "year                                               I-SKILLS\n",
      ")                                                  I-SKILLS\n",
      "AD                                                 O\n",
      "##DI                                               X\n",
      "##TI                                               X\n",
      "##ON                                               X\n",
      "##AL                                               X\n",
      "IN                                                 O\n",
      "##F                                                X\n",
      "##OR                                               X\n",
      "##MA                                               X\n",
      "##TI                                               X\n",
      "##ON                                               X\n",
      "Technical                                          O\n",
      "Skills                                             O\n",
      "https                                              O\n",
      ":                                                  X\n",
      "/                                                  X\n",
      "/                                                  X\n",
      "www                                                X\n",
      ".                                                  X\n",
      "indeed                                             X\n",
      ".                                                  X\n",
      "com                                                X\n",
      "/                                                  X\n",
      "r                                                  X\n",
      "/                                                  X\n",
      "A                                                  X\n",
      "##b                                                X\n",
      "##his                                              X\n",
      "##he                                               X\n",
      "##k                                                X\n",
      "-                                                  X\n",
      "J                                                  X\n",
      "##ha                                               X\n",
      "/                                                  X\n",
      "10                                                 X\n",
      "##e                                                X\n",
      "##7                                                X\n",
      "##a                                                X\n",
      "##8                                                X\n",
      "##c                                                X\n",
      "##b                                                X\n",
      "##7                                                X\n",
      "##32                                               X\n",
      "##b                                                X\n",
      "##c                                                X\n",
      "##43                                               X\n",
      "##a                                                X\n",
      "?                                                  X\n",
      "is                                                 X\n",
      "##id                                               X\n",
      "=                                                  X\n",
      "re                                                 X\n",
      "##x                                                X\n",
      "-                                                  X\n",
      "download                                           X\n",
      "&                                                  X\n",
      "i                                                  X\n",
      "##k                                                X\n",
      "##w                                                X\n",
      "=                                                  X\n",
      "download                                           X\n",
      "-                                                  X\n",
      "top                                                X\n",
      "&                                                  X\n",
      "co                                                 X\n",
      "=                                                  X\n",
      "IN                                                 X\n",
      "•                                                  I-SKILLS\n",
      "Programming                                        I-SKILLS\n",
      "language                                           I-SKILLS\n",
      ":                                                  I-SKILLS\n",
      "C                                                  I-SKILLS\n",
      ",                                                  I-SKILLS\n",
      "C                                                  I-SKILLS\n",
      "+                                                  X\n",
      "+                                                  X\n",
      ",                                                  I-SKILLS\n",
      "Java                                               I-SKILLS\n",
      "•                                                  I-SKILLS\n",
      "Oracle                                             I-SKILLS\n",
      "People                                             I-SKILLS\n",
      "##S                                                X\n",
      "##oft                                              X\n",
      "•                                                  I-SKILLS\n",
      "Internet                                           I-SKILLS\n",
      "Of                                                 I-SKILLS\n",
      "Things                                             I-SKILLS\n",
      "•                                                  I-SKILLS\n",
      "Machine                                            I-SKILLS\n",
      "Learning                                           I-SKILLS\n",
      "•                                                  I-SKILLS\n",
      "Database                                           I-SKILLS\n",
      "Management                                         I-SKILLS\n",
      "System                                             I-SKILLS\n",
      "•                                                  I-SKILLS\n",
      "Computer                                           I-SKILLS\n",
      "Networks                                           I-SKILLS\n",
      "•                                                  I-SKILLS\n",
      "Operating                                          I-SKILLS\n",
      "System                                             I-SKILLS\n",
      "worked                                             I-SKILLS\n",
      "on                                                 O\n",
      ":                                                  I-SKILLS\n",
      "Linux                                              I-SKILLS\n",
      ",                                                  I-SKILLS\n",
      "Windows                                            I-SKILLS\n",
      ",                                                  I-SKILLS\n",
      "Mac                                                O\n",
      "Non                                                O\n",
      "-                                                  O\n",
      "Technical                                          O\n",
      "Skills                                             O\n",
      "•                                                  I-SKILLS\n",
      "Hon                                                O\n",
      "##est                                              X\n",
      "and                                                I-SKILLS\n",
      "Hard                                               I-SKILLS\n",
      "-                                                  O\n",
      "Working                                            O\n",
      "•                                                  I-SKILLS\n",
      "To                                                 O\n",
      "##ler                                              X\n",
      "##ant                                              X\n",
      "and                                                I-SKILLS\n",
      "F                                                  I-SKILLS\n",
      "##lex                                              X\n",
      "##ible                                             X\n",
      "to                                                 O\n",
      "Different                                          I-SKILLS\n",
      "Sit                                                O\n",
      "##uations                                          X\n",
      "•                                                  I-SKILLS\n",
      "Pol                                                I-SKILLS\n",
      "##ite                                              X\n",
      "and                                                I-SKILLS\n",
      "Cal                                                O\n",
      "##m                                                X\n",
      "•                                                  I-SKILLS\n",
      "Team                                               I-SKILLS\n",
      "-                                                  X\n",
      "Player                                             I-SKILLS\n",
      "[SEP]                                              [SEP]\n"
     ]
    }
   ],
   "source": [
    "bert_predict(df.iloc[0][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1683644017630,
     "user": {
      "displayName": "Wong Yun Jet",
      "userId": "09982030126116333359"
     },
     "user_tz": -480
    },
    "id": "1-dC6ODN_miW",
    "outputId": "a4827264-747b-4a54-e75a-0b2bc87a2f40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]                                              [CLS]\n",
      "A                                                  B-NAME\n",
      "##b                                                X\n",
      "##his                                              X\n",
      "##he                                               X\n",
      "##k                                                X\n",
      "J                                                  L-NAME\n",
      "##ha                                               X\n",
      "Application                                        B-DESIG\n",
      "Development                                        I-DESIG\n",
      "Associate                                          L-DESIG\n",
      "-                                                  O\n",
      "A                                                  O\n",
      "##cc                                               X\n",
      "##ent                                              X\n",
      "##ure                                              X\n",
      "Bengal                                             U-LOC\n",
      "##uru                                              X\n",
      ",                                                  O\n",
      "Karnataka                                          O\n",
      "-                                                  O\n",
      "Em                                                 O\n",
      "##ail                                              X\n",
      "me                                                 O\n",
      "on                                                 O\n",
      "Indeed                                             O\n",
      ":                                                  O\n",
      "indeed                                             O\n",
      ".                                                  X\n",
      "com                                                X\n",
      "/                                                  X\n",
      "r                                                  X\n",
      "/                                                  X\n",
      "A                                                  X\n",
      "##b                                                X\n",
      "##his                                              X\n",
      "##he                                               X\n",
      "##k                                                X\n",
      "-                                                  X\n",
      "J                                                  X\n",
      "##ha                                               X\n",
      "/                                                  X\n",
      "10                                                 X\n",
      "##e                                                X\n",
      "##7                                                X\n",
      "##a                                                X\n",
      "##8                                                X\n",
      "##c                                                X\n",
      "##b                                                X\n",
      "##7                                                X\n",
      "##32                                               X\n",
      "##b                                                X\n",
      "##c                                                X\n",
      "##43                                               X\n",
      "##a                                                X\n",
      "•                                                  O\n",
      "To                                                 O\n",
      "work                                               O\n",
      "for                                                O\n",
      "an                                                 O\n",
      "organization                                       O\n",
      "which                                              O\n",
      "provides                                           O\n",
      "me                                                 O\n",
      "the                                                O\n",
      "opportunity                                        O\n",
      "to                                                 O\n",
      "improve                                            O\n",
      "my                                                 O\n",
      "skills                                             O\n",
      "and                                                O\n",
      "knowledge                                          O\n",
      "for                                                O\n",
      "my                                                 O\n",
      "individual                                         O\n",
      "and                                                O\n",
      "company                                            O\n",
      "'                                                  O\n",
      "s                                                  X\n",
      "growth                                             O\n",
      "in                                                 O\n",
      "best                                               O\n",
      "possible                                           O\n",
      "ways                                               O\n",
      ".                                                  O\n",
      "Will                                               O\n",
      "##ing                                              X\n",
      "to                                                 O\n",
      "relocate                                           O\n",
      "to                                                 O\n",
      ":                                                  O\n",
      "Bangalore                                          O\n",
      ",                                                  O\n",
      "Karnataka                                          O\n",
      "W                                                  O\n",
      "##OR                                               X\n",
      "##K                                                X\n",
      "E                                                  O\n",
      "##X                                                X\n",
      "##P                                                X\n",
      "##ER                                               X\n",
      "##IE                                               X\n",
      "##NC                                               X\n",
      "##E                                                X\n",
      "Application                                        B-DESIG\n",
      "Development                                        I-DESIG\n",
      "Associate                                          L-DESIG\n",
      "A                                                  O\n",
      "##cc                                               X\n",
      "##ent                                              X\n",
      "##ure                                              X\n",
      "-                                                  O\n",
      "November                                           O\n",
      "2017                                               O\n",
      "to                                                 O\n",
      "Present                                            O\n",
      "Role                                               O\n",
      ":                                                  O\n",
      "Currently                                          O\n",
      "working                                            O\n",
      "on                                                 O\n",
      "Cha                                                O\n",
      "##t                                                X\n",
      "-                                                  O\n",
      "b                                                  O\n",
      "##ot                                               X\n",
      ".                                                  O\n",
      "Dev                                                O\n",
      "##elo                                              X\n",
      "##ping                                             X\n",
      "Back                                               O\n",
      "##end                                              X\n",
      "Oracle                                             U-COMPANY\n",
      "People                                             O\n",
      "##S                                                X\n",
      "##oft                                              X\n",
      "Que                                                O\n",
      "##ries                                             X\n",
      "for                                                O\n",
      "the                                                O\n",
      "Bo                                                 O\n",
      "##t                                                X\n",
      "which                                              O\n",
      "will                                               O\n",
      "be                                                 O\n",
      "triggered                                          O\n",
      "based                                              O\n",
      "on                                                 O\n",
      "given                                              O\n",
      "input                                              O\n",
      ".                                                  [SEP]\n",
      "Also                                               O\n",
      ",                                                  O\n",
      "Training                                           O\n",
      "the                                                O\n",
      "b                                                  O\n",
      "##ot                                               X\n",
      "for                                                O\n",
      "different                                          O\n",
      "possible                                           O\n",
      "utter                                              O\n",
      "##ance                                             X\n",
      "##s                                                X\n",
      "(                                                  O\n",
      "Both                                               X\n",
      "positive                                           O\n",
      "and                                                O\n",
      "negative                                           O\n",
      ")                                                  O\n",
      ",                                                  O\n",
      "which                                              O\n",
      "will                                               O\n",
      "be                                                 O\n",
      "given                                              O\n",
      "as                                                 O\n",
      "input                                              O\n",
      "by                                                 O\n",
      "the                                                O\n",
      "user                                               O\n",
      ".                                                  O\n",
      "E                                                  O\n",
      "##D                                                X\n",
      "##UC                                               X\n",
      "##AT                                               X\n",
      "##ION                                              X\n",
      "B                                                  B-DEG\n",
      ".                                                  X\n",
      "E                                                  X\n",
      "in                                                 I-DEG\n",
      "Information                                        I-DEG\n",
      "science                                            I-DEG\n",
      "and                                                I-DEG\n",
      "engineering                                        I-DEG\n",
      "B                                                  B-CLG\n",
      ".                                                  X\n",
      "v                                                  X\n",
      ".                                                  X\n",
      "b                                                  X\n",
      "college                                            I-CLG\n",
      "of                                                 I-CLG\n",
      "engineering                                        I-CLG\n",
      "and                                                I-CLG\n",
      "technology                                         L-CLG\n",
      "-                                                  O\n",
      "Hu                                                 O\n",
      "##b                                                X\n",
      "##li                                               X\n",
      ",                                                  O\n",
      "Karnataka                                          O\n",
      "August                                             O\n",
      "2013                                               O\n",
      "to                                                 O\n",
      "June                                               O\n",
      "2017                                               U-GRADYEAR\n",
      "12th                                               O\n",
      "in                                                 O\n",
      "Mathematics                                        O\n",
      "Wood                                               B-CLG\n",
      "##bine                                             X\n",
      "modern                                             I-CLG\n",
      "school                                             I-CLG\n",
      "April                                              O\n",
      "2011                                               O\n",
      "to                                                 O\n",
      "March                                              O\n",
      "2013                                               U-GRADYEAR\n",
      "10th                                               O\n",
      "Ken                                                B-CLG\n",
      "##dr                                               X\n",
      "##iya                                              X\n",
      "V                                                  L-CLG\n",
      "##idy                                              X\n",
      "##alaya                                            X\n",
      "April                                              O\n",
      "2001                                               O\n",
      "to                                                 O\n",
      "March                                              O\n",
      "2011                                               O\n",
      "SK                                                 O\n",
      "##IL                                               X\n",
      "##LS                                               X\n",
      "C                                                  B-SKILLS\n",
      "(                                                  I-SKILLS\n",
      "Less                                               X\n",
      "than                                               I-SKILLS\n",
      "1                                                  I-SKILLS\n",
      "year                                               I-SKILLS\n",
      ")                                                  I-SKILLS\n",
      ",                                                  I-SKILLS\n",
      "Database                                           I-SKILLS\n",
      "(                                                  I-SKILLS\n",
      "Less                                               X\n",
      "than                                               I-SKILLS\n",
      "1                                                  I-SKILLS\n",
      "year                                               I-SKILLS\n",
      ")                                                  I-SKILLS\n",
      ",                                                  I-SKILLS\n",
      "Database                                           I-SKILLS\n",
      "Management                                         I-SKILLS\n",
      "(                                                  I-SKILLS\n",
      "Less                                               X\n",
      "than                                               I-SKILLS\n",
      "1                                                  I-SKILLS\n",
      "year                                               I-SKILLS\n",
      ")                                                  I-SKILLS\n",
      ",                                                  I-SKILLS\n",
      "Database                                           I-SKILLS\n",
      "Management                                         I-SKILLS\n",
      "System                                             I-SKILLS\n",
      "(                                                  I-SKILLS\n",
      "Less                                               X\n",
      "than                                               I-SKILLS\n",
      "1                                                  I-SKILLS\n",
      "year                                               I-SKILLS\n",
      ")                                                  I-SKILLS\n",
      ",                                                  I-SKILLS\n",
      "Java                                               I-SKILLS\n",
      "(                                                  I-SKILLS\n",
      "Less                                               X\n",
      "than                                               I-SKILLS\n",
      "1                                                  I-SKILLS\n",
      "year                                               I-SKILLS\n",
      ")                                                  I-SKILLS\n",
      "AD                                                 O\n",
      "##DI                                               X\n",
      "##TI                                               X\n",
      "##ON                                               X\n",
      "##AL                                               X\n",
      "IN                                                 O\n",
      "##F                                                X\n",
      "##OR                                               X\n",
      "##MA                                               X\n",
      "##TI                                               X\n",
      "##ON                                               X\n",
      "Technical                                          O\n",
      "Skills                                             O\n",
      "https                                              O\n",
      ":                                                  X\n",
      "/                                                  X\n",
      "/                                                  X\n",
      "www                                                X\n",
      ".                                                  X\n",
      "indeed                                             X\n",
      ".                                                  X\n",
      "com                                                X\n",
      "/                                                  X\n",
      "r                                                  X\n",
      "/                                                  X\n",
      "A                                                  X\n",
      "##b                                                X\n",
      "##his                                              X\n",
      "##he                                               X\n",
      "##k                                                X\n",
      "-                                                  X\n",
      "J                                                  X\n",
      "##ha                                               X\n",
      "/                                                  X\n",
      "10                                                 X\n",
      "##e                                                X\n",
      "##7                                                X\n",
      "##a                                                X\n",
      "##8                                                X\n",
      "##c                                                X\n",
      "##b                                                X\n",
      "##7                                                X\n",
      "##32                                               X\n",
      "##b                                                X\n",
      "##c                                                X\n",
      "##43                                               X\n",
      "##a                                                X\n",
      "?                                                  X\n",
      "is                                                 X\n",
      "##id                                               X\n",
      "=                                                  X\n",
      "re                                                 X\n",
      "##x                                                X\n",
      "-                                                  X\n",
      "download                                           X\n",
      "&                                                  X\n",
      "i                                                  X\n",
      "##k                                                X\n",
      "##w                                                X\n",
      "=                                                  X\n",
      "download                                           X\n",
      "-                                                  X\n",
      "top                                                X\n",
      "&                                                  X\n",
      "co                                                 X\n",
      "=                                                  X\n",
      "IN                                                 X\n",
      "•                                                  I-SKILLS\n",
      "Programming                                        I-SKILLS\n",
      "language                                           I-SKILLS\n",
      ":                                                  I-SKILLS\n",
      "C                                                  I-SKILLS\n",
      ",                                                  I-SKILLS\n",
      "C                                                  I-SKILLS\n",
      "+                                                  X\n",
      "+                                                  X\n",
      ",                                                  I-SKILLS\n",
      "Java                                               I-SKILLS\n",
      "•                                                  I-SKILLS\n",
      "Oracle                                             I-SKILLS\n",
      "People                                             I-SKILLS\n",
      "##S                                                X\n",
      "##oft                                              X\n",
      "•                                                  I-SKILLS\n",
      "Internet                                           I-SKILLS\n",
      "Of                                                 I-SKILLS\n",
      "Things                                             I-SKILLS\n",
      "•                                                  I-SKILLS\n",
      "Machine                                            I-SKILLS\n",
      "Learning                                           I-SKILLS\n",
      "•                                                  I-SKILLS\n",
      "Database                                           I-SKILLS\n",
      "Management                                         I-SKILLS\n",
      "System                                             I-SKILLS\n",
      "•                                                  I-SKILLS\n",
      "Computer                                           I-SKILLS\n",
      "Networks                                           I-SKILLS\n",
      "•                                                  I-SKILLS\n",
      "Operating                                          I-SKILLS\n",
      "System                                             I-SKILLS\n",
      "worked                                             I-SKILLS\n",
      "on                                                 O\n",
      ":                                                  I-SKILLS\n",
      "Linux                                              I-SKILLS\n",
      ",                                                  I-SKILLS\n",
      "Windows                                            I-SKILLS\n",
      ",                                                  I-SKILLS\n",
      "Mac                                                O\n",
      "Non                                                O\n",
      "-                                                  O\n",
      "Technical                                          O\n",
      "Skills                                             O\n",
      "•                                                  I-SKILLS\n",
      "Hon                                                O\n",
      "##est                                              X\n",
      "and                                                I-SKILLS\n",
      "Hard                                               I-SKILLS\n",
      "-                                                  O\n",
      "Working                                            O\n",
      "•                                                  I-SKILLS\n",
      "To                                                 O\n",
      "##ler                                              X\n",
      "##ant                                              X\n",
      "and                                                I-SKILLS\n",
      "F                                                  I-SKILLS\n",
      "##lex                                              X\n",
      "##ible                                             X\n",
      "to                                                 O\n",
      "Different                                          I-SKILLS\n",
      "Sit                                                O\n",
      "##uations                                          X\n",
      "•                                                  I-SKILLS\n",
      "Pol                                                I-SKILLS\n",
      "##ite                                              X\n",
      "and                                                I-SKILLS\n",
      "Cal                                                O\n",
      "##m                                                X\n",
      "•                                                  I-SKILLS\n",
      "Team                                               I-SKILLS\n",
      "-                                                  X\n",
      "Player                                             I-SKILLS\n",
      "[SEP]                                              [SEP]\n"
     ]
    }
   ],
   "source": [
    "bert_predict(data[0][0])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
